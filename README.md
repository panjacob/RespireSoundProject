Optymalizacja struktur i oblicze&#324; w sieciach neuronowych</span></p><p class="c33 c53 c25"><span class="c23 c13"></span></p><p class="c33 c53"><span class="c23 c13">Projekt 2023</span></p><p class="c26 c25"><span class="c23 c13"></span></p><p class="c33 c53"><span class="c23 c13">Piotr Durawa 176300</span></p><p class="c33 c53"><span class="c23 c13">Jakub Kwiatkowski 192237</span></p><p class="c33 c53 c25"><span class="c23 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0 start" start="1"><li class="c26 c52 li-bullet-0"><span class="c23 c13">Etap I - Wyb&oacute;r zagadnienia do realizacji</span></li></ol><p class="c26 c25"><span class="c23 c13"></span></p><p class="c4"><span class="c62">Zagadnienie:</span><span class="c31 c13">&nbsp;Klasyfikacja nagra&#324; cykli oddechowych w celu rozpoznawania potencjalnych oznak chor&oacute;b uk&#322;adu oddechowego.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c62">Uzasadnienie wyboru celu: </span><span>W tradycyjnym podej&#347;ciu rozpoznawanie oznak chor&oacute;b uk&#322;adu oddechowego takich jak &#347;wisty, trzaski wymaga zaanga&#380;owania lekarza i wi&#261;&#380;e si&#281; z </span><span class="c62">ocen&#261; subiektywn&#261;</span><span class="c31 c13">. Wykorzystanie technik uczenia g&#322;&#281;bokiego mo&#380;e pozwoli&#263; na zbudowanie urz&#261;dze&#324; wspomagaj&#261;cych eksperta.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c13 c48 c47">Czego oczekuje si&#281; od optymalizacji?</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c16"><span>Optymalizacja mo&#380;e w tym przypadku umo&#380;liwi&#263; wykorzystanie modelu na urz&#261;dzeniach medycznych o ograniczonych zasobach sprz&#281;towych lub urz&#261;dzeniach przeno&#347;nych s&#322;u&#380;&#261;cych potencjalnie do monitorowania oddechu. Istotne jest w tym celu </span><span class="c62">skr&oacute;cenie czasu wnioskowania</span><span>&nbsp;oraz</span><span class="c62">&nbsp;redukcja rozmiaru modelu</span><span class="c31 c13">.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c62">Zbi&oacute;r danych:</span><span>&nbsp;ICBHI Respiratory Sound Database </span><span class="c64">[1]</span></p><p class="c4"><span class="c31 c13">Zbi&oacute;r ten zawiera 5.5 godzin nagra&#324; sk&#322;adaj&#261;cych si&#281; z 6898 cykli oddechowych. Dane oznaczone s&#261; klasami:</span></p><ul class="c50 lst-kix_959uj5rx5ebh-0 start"><li class="c4 c52 li-bullet-0"><span class="c31 c13">crackles (trzaski) - 1864 pr&oacute;bki,</span></li></ul><ul class="c50 lst-kix_my1j5w5loqk2-0 start"><li class="c4 c52 li-bullet-0"><span class="c31 c13">wheezes (&#347;wisty) - 886 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">both (&#347;wisty i trzaski) - 506 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span>oddech normalny - 3642 pr&oacute;bki</span></li></ul><p class="c4"><span class="c31 c13">Dane by&#322;y zbierane z wykorzystaniem czterech r&oacute;&#380;nych urz&#261;dze&#324;. Nagrania s&#261; o r&oacute;&#380;nej d&#322;ugo&#347;ci. By&#322;y zbierane z 7 r&oacute;&#380;nych cz&#281;&#347;ci cia&#322;a w trybie multi channel (jednocze&#347;nie) lub single channel (sekwencyjnie). </span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c13 c48 c47">Zadania:</span></p><ul class="c50 lst-kix_1ct4hufdi4cb-0 start"><li class="c4 c52 li-bullet-0"><span>klasyfikacja 4-klasowa: {oddech w normie, &#347;wist, trzask, &#347;wist i trzask} - </span><span class="c13 c48 c47">podstawowe</span></li><li class="c4 c52 li-bullet-0"><span>klasyfikacja 2-klasowa: {oddech w normie, oddech nieprawid&#322;owy} - </span><span class="c13 c48 c47">pochodne</span></li></ul><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Klasa &ldquo;oddech nieprawid&#322;owy&rdquo; agreguje pr&oacute;bki nale&#380;&#261;ce do klas {&#347;wist, trzask, &#347;wist i trzask}.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c62">Reprezentacja:</span><span class="c31 c13">&nbsp;Mel-spektrogram/MFCC</span></p><p class="c4 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="2"><li class="c4 c52 li-bullet-0"><span class="c13 c23">ETAP II - Wyb&oacute;r danych i modelu</span></li></ol><p class="c4 c25"><span class="c13 c48 c47"></span></p><p class="c4"><span class="c62">Zbi&oacute;r danych:</span><span class="c31 c13">&nbsp;ICBHI Respiratory Sound Database [1]</span></p><p class="c4"><span class="c31 c13">Zbi&oacute;r ten zawiera 5.5 godzin nagra&#324; sk&#322;adaj&#261;cych si&#281; z 6898 cykli oddechowych. Dane oznaczone s&#261; klasami:</span></p><ul class="c50 lst-kix_959uj5rx5ebh-0"><li class="c4 c52 li-bullet-0"><span class="c31 c13">crackles (trzaski) - 1864 pr&oacute;bki,</span></li></ul><ul class="c50 lst-kix_my1j5w5loqk2-0"><li class="c4 c52 li-bullet-0"><span class="c31 c13">wheezes (&#347;wisty) - 886 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">both (&#347;wisty i trzaski) - 506 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">oddech normalny - 3642 pr&oacute;bki</span></li></ul><p class="c4"><span class="c31 c13">Dane by&#322;y zbierane z wykorzystaniem czterech r&oacute;&#380;nych urz&#261;dze&#324;. Nagrania s&#261; o r&oacute;&#380;nej d&#322;ugo&#347;ci. By&#322;y zbierane z 7 r&oacute;&#380;nych cz&#281;&#347;ci cia&#322;a w trybie multi channel (jednocze&#347;nie) lub single channel (sekwencyjnie). </span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c62">Model: </span><span>LungAttn </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?xZfTfl&amp;sa=D&amp;source=editors&amp;ust=1700747230249476&amp;usg=AOvVaw2FYyWqo11wPZSYUVaFPGFm">[1]</a></span><span>&nbsp;</span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?r51mVc&amp;sa=D&amp;source=editors&amp;ust=1700747230249992&amp;usg=AOvVaw33AiYHpFraWZMJZOYuYnJN">[2]</a></span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Model LungAttn bazuje na architekturze ResNet. Autorzy wprowadzili do modelu warstwy splotowe rozszerzone o mechanizm atencji (ang. Attention augmented convolution, AAConv). Polega to na niezale&#380;nym przetworzeniu wej&#347;ciowej mapy cech przez warstw&#281; splotow&#261; oraz mechanizm atencji, a nast&#281;pnie konkatenacji wyj&#347;ciowych map cech. Wykorzystanie mechanizmu atencji uzasadnione zosta&#322;o potrzeb&#261; uwzgl&#281;dnienia zale&#380;no&#347;ci czasowych i cz&#281;stotliwo&#347;ciowych na spektrogramach bez wzgl&#281;du na lokalizacj&#281; cech na obrazie. Architektur&#281; modelu przedstawiono na rysunku 1. Na pocz&#261;tku zastosowano warstw&#281; splotow&#261;, normalizacji grupowej (ang. group normalization, GP), poolingu oraz kilka blok&oacute;w ResNet, aby dokona&#263; ekstrakcji map cech o </span><span class="c62">du&#380;ym polu recepcyjnym</span><span>, kt&oacute;ra nast&#281;pnie jest przetwarzana przez bloczek zawieraj&#261;cy AAConv w celu uwzgl&#281;dnienia </span><span class="c62">globalnych interakcji pomi&#281;dzy cechami</span><span class="c31 c13">. Wyj&#347;cie bloczku AAResNet przetwarzane jest dalej przez kolejny bloczek ResNet II, warstw&#281; normalizacji grupowej, warstw&#281; poolingu, a na ko&#324;cu przez warstwy w pe&#322;ni po&#322;&#261;czone (ang. fully-connected, FC). Po warstwach w pe&#322;ni po&#322;&#261;czonych umieszczono warstwy Dropout.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 234.67px;"><img alt="" src="images/image31.png" style="width: 601.70px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c16 c20"><span>Rys. 1. Diagram przedstawiaj&#261;cy architektur&#281; modelu LungAttn </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?3R6iSS&amp;sa=D&amp;source=editors&amp;ust=1700747230251044&amp;usg=AOvVaw2l-TsnD7dVaaBfpWhLwpRI">[1]</a></span><span>.</span></p><p class="c14 c20 c53 c25"><span class="c31 c13"></span></p><p class="c14 c20 c53 c25"><span class="c31 c13"></span></p><p class="c14 c20 c53 c25"><span class="c31 c13"></span></p><p class="c14 c20 c53 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c62">Uzasadnienie wyboru danych i modelu:</span><span class="c31 c13">&nbsp;</span></p><p class="c16 c17"><span class="c31 c13">Zbi&oacute;r danych wynika&#322; z przyj&#281;tego zagadnienia, kt&oacute;re wybrano tak, aby mo&#380;liwe by&#322;o okre&#347;lenie nowego zadania na zbiorze danych. Jednocze&#347;nie wybrano zbi&oacute;r benchmarkowy pozwalaj&#261;cy na por&oacute;wnywanie wynik&oacute;w. Kierowano si&#281; r&oacute;wnie&#380; aspektami praktycznymi. Zadbano o to, aby zbi&oacute;r danych nie by&#322; zbyt z&#322;o&#380;ony w stosunku do wymaga&#324; projektu. </span></p><p class="c16"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Model wybrano spo&#347;r&oacute;d dost&#281;pnych na stronie Papers With Code dla zagadnienia klasyfikacji nagra&#324; cykli oddechowych </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?6oBae6&amp;sa=D&amp;source=editors&amp;ust=1700747230251974&amp;usg=AOvVaw3NPdVIZEYy2Q5xBp2XRuAU">[3]</a></span><span class="c31 c13">. Podczas wyboru modelu kierowano si&#281; tym, aby nie by&#322; zbyt du&#380;y w stosunku do z&#322;o&#380;ono&#347;ci zagadnienia oraz by&#322; mo&#380;liwy jego trening na platformie sprz&#281;towej o ograniczonych zasobach.</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c13 c48 c47">Scharakteryzowanie oryginalnych danych:</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span>G&#322;&oacute;wne cechy charakterystyczne zbioru danych </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?G0jna0&amp;sa=D&amp;source=editors&amp;ust=1700747230252782&amp;usg=AOvVaw1IglzRPBTYjNxhFuhY_up-">[4]</a></span><span class="c31 c13">&nbsp;przedstawiono w tabeli 1.</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c31 c13">Tabela 1. Charakterystyka zbioru danych.</span></p><a id="t.b95753c2098bf3267b9be1cca9b4f02293ec1254"></a><a id="t.0"></a><table class="c37"><tr class="c88"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Zbi&oacute;r klas</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c4"><span class="c58">{</span><span class="c36">oddech w normie</span><span class="c58">, </span><span class="c36">&#347;wist</span><span class="c58">, </span><span class="c36">trzask</span><span class="c58">, </span><span class="c36">&#347;wist i trzask</span><span class="c11">}</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba przyk&#322;ad&oacute;w na klas&#281;</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">{3642 ,886, 1864, 506 }</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Format danych</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">audio, rozszerzenie .wav, cz&#281;stotliwo&#347;&#263; pr&oacute;bkowania 44.1 kHz, bitrate 1058 kbps</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">&#321;&#261;czny czas nagra&#324; audio</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">5.5 h</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba pacjent&oacute;w</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">126</span></p></td></tr></table><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c31 c13">Dane by&#322;y zbierane z 7 r&oacute;&#380;nych lokalizacji klatki piersiowej. Dane s&#261; heterogeniczne - zbierane by&#322;y za pomoc&#261; czterech r&oacute;&#380;nych urz&#261;dze&#324;:</span></p><ul class="c50 lst-kix_8suvl9k1enp0-0 start"><li class="c16 c52 li-bullet-0"><span class="c31 c13">AKG C417L Microphone,</span></li><li class="c16 c52 li-bullet-0"><span class="c31 c13">3M Littmann Classic II SE Stethoscope,</span></li><li class="c16 c52 li-bullet-0"><span class="c31 c13">3M Litmmann 3200 Electronic Stethoscope,</span></li><li class="c16 c52 li-bullet-0"><span>WelchAllyn Meditron Master Elite Electronic Stet</span><span>hoscop</span><span class="c31 c13">e</span></li></ul><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span>Z danych najpierw wyci&#281;to cykle oddechowe za pomoc&#261; skryptu </span><span class="c45">clip_breath_cycles.py</span><span>. Nast&#281;pnie wykonano preprocessing, w kt&oacute;rym dane zosta&#322;y przetworzone do postaci spektrogram&oacute;w. R&oacute;&#380;ne parametry transformaty TQWT </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?uxtL4F&amp;sa=D&amp;source=editors&amp;ust=1700747230257611&amp;usg=AOvVaw3DDMGLGD6byeyFnZTV1rTz">[1]</a></span><span>&nbsp;pozwoli&#322;y uzyska&#263; dla ka&#380;dego cyklu trzy spektrogramy o r&oacute;&#380;nej charakterystyce.</span><span>&nbsp;Wykorzystano domy&#347;lne parametry transformaty TQWT dost&#281;pne w repozytorium projektu </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?jsmN4M&amp;sa=D&amp;source=editors&amp;ust=1700747230258028&amp;usg=AOvVaw0wSlROzYqnWrg5g8InWe_E">[2]</a></span><span class="c31 c13">. </span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c13 c48 c47">Scharakteryzowanie oryginalnego modelu:</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span>Charakterystyk&#281; oryginalnego modelu LungAttn przedstawiono w tabeli 2. Dane statystyczne wyznaczono po treningu modelu przez 100 epok. W przypadku pomiaru czasu wnioskowania na GPU wykorzystano zalecenia podane na blogu Geifmana </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?Q21YaZ&amp;sa=D&amp;source=editors&amp;ust=1700747230258785&amp;usg=AOvVaw2S-FVeSyfivHS6eRV4dxZb">[5]</a></span><span>. Obliczenia wykonywane r&oacute;wnolegle na CPU i GPU s&#261; asynchroniczne. Oznacza to, &#380;e CPU po sko&#324;czeniu pracy mo&#380;e przej&#347;&#263; do wykonywania dalszych dzia&#322;a&#324; np. pomiaru czasu, nawet je&#347;li proces obliczeniowy na GPU jeszcze si&#281; nie sko&#324;czy&#322;. Z tego wzgl&#281;du wykorzystano metod&#281; torch.cuda.Event() do pomiaru czasu na GPU oraz metod&#281; torch.cuda.synchronize(), aby zatrzyma&#263; CPU a&#380; do czasu sko&#324;czenia oblicze&#324; na GPU. Przed wykonaniem test&oacute;w w&#322;a&#347;ciwych przeprowadzono 10 iteracji rozgrzewkowych w celu inicjalizacji GPU. Porcja danych, na kt&oacute;rej wykonywano pomiary zosta&#322;a przeniesiona na GPU przez rozpocz&#281;ciem procedury, zatem otrzymane wyniki nie uwzgl&#281;dniaj&#261; czasu potrzebnego na przeniesienie danych do pami&#281;ci GPU.</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c31 c13">Tabela 2. Charakterystyka oryginalnego modelu LungAttn.</span></p><a id="t.b844a3ddb0f8f641a4b03e6f7bd8134ab9e3ac3c"></a><a id="t.1"></a><table class="c37"><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba parametr&oacute;w</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">711 900</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Rozmiar modelu</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">2.716 MB</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas treningu pojedynczej epoki (batchsize 128)</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">&#347;rednia: 11.99 s, odchylenie standardowe 0.42 s</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Wymagania pami&#281;ciowe (batchsize 128)</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">2600 MiB &nbsp;VRAM</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji na GPU (1 pr&oacute;bka)</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">&#347;rednia: 1.231 ms, odchylenie standardowe 0.183 ms</span></p></td></tr><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji na CPU (1 pr&oacute;bka)</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">&#347;rednia: 4.941 ms, odchylenie standardowe:</span></p><p class="c14"><span class="c11">0.172 ms</span></p></td></tr></table><p class="c16 c25"><span class="c13 c48 c47"></span></p><p class="c16 c25"><span class="c13 c48 c47"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="3"><li class="c4 c52 li-bullet-0"><span class="c23 c13">ETAP III - Okre&#347;lenie zadania docelowego i przygotowanie danych</span></li></ol><p class="c4 c25"><span class="c23 c13"></span></p><p class="c26"><span class="c31 c13">Do nowego zadania zosta&#322; przygotowany nowy zbi&oacute;r danych. Oryginalny zbi&oacute;r danych prezentuje si&#281; nast&#281;puj&#261;co:</span></p><ul class="c50 lst-kix_959uj5rx5ebh-0"><li class="c4 c52 li-bullet-0"><span class="c31 c13">crackles (trzaski) - 1864 pr&oacute;bki,</span></li></ul><ul class="c50 lst-kix_my1j5w5loqk2-0"><li class="c4 c52 li-bullet-0"><span class="c31 c13">wheezes (&#347;wisty) - 886 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">both (&#347;wisty i trzaski) - 506 pr&oacute;bek,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">oddech normalny - 3642 pr&oacute;bki</span></li></ul><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Trening modelu bazowego dla 4 klas wygl&#261;da nast&#281;puj&#261;co. Podczas treningu mo&#380;na zauwa&#380;y&#263; overfitting po oko&#322;o 50 epoce. Wyniki walidacyjne po 50 epoce s&#261; ni&#380;sze. </span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 361.33px;"><img alt="" src="images/image33.png" style="width: 601.70px; height: 361.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c16 c20"><span class="c31 c13">Rys. 2. Wykres przedstawiaj&#261;cy trening dla modelu bazowego dla 4 klas</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">W nowym zbiorze danych po&#322;&#261;czono pr&oacute;bki &ldquo;crackles&rdquo;, &ldquo;wheezes&rdquo; oraz &ldquo;both&rdquo;. Umo&#380;liwia to podzielenie zbioru na klas&#281;, gdzie nie wyst&#281;puj&#261; &#380;adne zaburzenia oddechu i klas&#281;, gdzie wyst&#281;puj&#261; trzaski lub/i &#347;wisty w oddechu. &nbsp;W rezultacie otrzymano dwie klasy:</span></p><ul class="c50 lst-kix_my1j5w5loqk2-0"><li class="c4 c52 li-bullet-0"><span class="c31 c13">oddech nienormalny- 3256 pr&oacute;bki,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">oddech normalny - 3642 pr&oacute;bki</span></li></ul><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Pr&oacute;bki zosta&#322;y zaszumione poprzez wykorzystanie funkcji, kt&oacute;ra odwraca podan&#261; warto&#347;&#263; z okre&#347;lonym prawdopodobie&#324;stwem. W bibliotece random ustawiono r&#281;cznie zadane ziarno dla generatora liczb pseudolosowych, aby zapewni&#263; powtarzalno&#347;&#263; wynik&oacute;w.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4 c49"><span class="c51 c45">def </span><span class="c24">flip_with_probability</span><span class="c1">(value, probability)</span><span class="c24 c13">:</span></p><p class="c4 c49"><span class="c24">&nbsp; &nbsp;</span><span class="c51 c45">if </span><span class="c1">random.</span><span class="c24">random</span><span class="c1">() </span><span class="c24">&lt; </span><span class="c1">probability</span><span class="c24 c13">:</span></p><p class="c4 c49"><span class="c24">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c51 c45">return </span><span class="c6">1 </span><span class="c24">- </span><span class="c1 c13">value</span></p><p class="c4 c49"><span class="c1">&nbsp; &nbsp;</span><span class="c51 c45">else</span><span class="c24 c13">:</span></p><p class="c4 c49"><span class="c24">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c45 c51">return </span><span class="c1 c13">value</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Do kodu &#378;r&oacute;d&#322;owego zosta&#322;a zaimplementowana utworzona funkcja.</span></p><p class="c4 c49"><span class="c51 c45">if </span><span class="c6">crackles </span><span class="c24">== </span><span class="c6">0 </span><span class="c51 c45">and </span><span class="c6">wheezes </span><span class="c24">== </span><span class="c6">0</span><span class="c24 c13">:</span></p><p class="c4 c49"><span class="c24">&nbsp; &nbsp;</span><span class="c6">label </span><span class="c24">= flip_with_probability</span><span class="c1">(</span><span class="c6">0</span><span class="c1 c13">, probability_of_flip)</span></p><p class="c4 c49"><span class="c51 c45">else</span><span class="c24 c13">:</span></p><p class="c4 c49"><span class="c24">&nbsp; &nbsp;</span><span class="c6">label </span><span class="c24">= flip_with_probability</span><span class="c1">(</span><span class="c6">1</span><span class="c1 c13">, probability_of_flip)</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Utworzono zbiory danych z zaszumieniem wynosz&#261;cym 1%, 5% i 10%.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="4"><li class="c4 c52 li-bullet-0"><span class="c68">ETAP IV -</span><span class="c68">&nbsp;Douczenie oraz pomiary modelu odniesienia (baseline) </span><sup><a href="#cmnt1" id="cmnt_ref1">[a]</a></sup></li></ol><p class="c4"><span class="c31 c13">Nowy zbi&oacute;r wymaga klasyfikacji binarnej, dlatego na ko&#324;cu modelu wykorzystano funkcj&#281; Sigmoid. Oryginalny model zosta&#322; douczony do nowego zadania poprzez zamro&#380;enie pierwszej warstwy splotowej oraz wszystkich blok&oacute;w ResNet. Nowa architektura sieci prezentuje si&#281; nast&#281;puj&#261;co:</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">conv1</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_0_0</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_0_1</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_0</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_1</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_2</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_3</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_4</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_5</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">ResNet_6</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - zamro&#380;ona</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">norm0</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c58 c45 c61">self</span><span class="c1">.</span><span class="c24">relu0</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">pool0</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">flat</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">linear1</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">dropout1</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">linear2</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">dropout2</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">)</span></p><p class="c26 c49"><span class="c6">x </span><span class="c24">= </span><span class="c61 c58 c45">self</span><span class="c1">.</span><span class="c24">output_sigmoid</span><span class="c1">(</span><span class="c6">x</span><span class="c1 c13">) - nowe wyj&#347;cie</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c4"><span>Og&oacute;lne hiperparametry wykorzystywane podczas uczenia modeli w tym oraz w kolejnych podpunktach przedstawiono w tabeli 3. Do uczenia wykorzystano optymalizator SGD</span><span>&nbsp;</span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?Q15wpT&amp;sa=D&amp;source=editors&amp;ust=1700747230274084&amp;usg=AOvVaw2qaq5uJBWnnVvJ9vYd4gEk">[6]</a></span><span>&nbsp;oraz scheduler StepLR </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?0mE0Zl&amp;sa=D&amp;source=editors&amp;ust=1700747230274555&amp;usg=AOvVaw0WTrJb2z5o514FmODwJaLm">[7]</a></span><span>.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 3. Hiperparametry podczas treningu modelu binarnego.</span></p><a id="t.29951ed54f453e2ab7207a5c054fe03f8d0e9b7b"></a><a id="t.2"></a><table class="c37"><tr class="c21"><td class="c99" colspan="1" rowspan="1"><p class="c14"><span class="c11">Funkcja straty</span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c14"><span class="c11">Optymalizator</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">momentum</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c11">Learning</span></p><p class="c14"><span class="c11">rate (pocz&#261;tkowa</span></p><p class="c14"><span class="c11">warto&#347;&#263;)</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c11">weight decay</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c14"><span class="c11">Scheduler step, gamma</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c11">dropout0, dropout1,</span></p><p class="c14"><span class="c11">dropout2</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba kluczy, warto&#347;ci oraz g&#322;&oacute;w warstwy atencji</span></p></td></tr><tr class="c91"><td class="c99" colspan="1" rowspan="1"><p class="c14"><span class="c58">BCELoss() </span><span class="c64 c58"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?nHMRej&amp;sa=D&amp;source=editors&amp;ust=1700747230277783&amp;usg=AOvVaw1miI7YPuZM8aevSesD_Aw8">[8]</a></span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c14"><span class="c11">SGD</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.9</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.1</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.0</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c14"><span class="c11">(50, 0.1)</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c11">(0.25, 0.25, 0.25)</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c14"><span class="c11">(20, 4, 2)</span></p></td></tr></table><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Model wytrenowany na oryginalnym zbiorze (4 klasy) zosta&#322; wytrenowany na 100 epokach. Nast&#281;pnie model binarny zosta&#322; dotrenowany na 30 epokach. Obni&#380;ono learning rate z 0.1 do 0.01. &nbsp;Poni&#380;ej przedstawiono wyniki dotrenowanych modeli z 3 r&oacute;&#380;nymi poziomami zaszumienia zbioru.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 4. Miary dok&#322;adno&#347;ci dzia&#322;ania modelu odniesienia przy r&oacute;&#380;nych poziomach zaszumienia.</span></p><a id="t.586b6ed718790cb2e65d2a1be3608dd16d5b50a5"></a><a id="t.3"></a><table class="c37"><tr class="c93"><td class="c76" colspan="1" rowspan="1"><p class="c33 c53"><span class="c13 c36 c47">Poziom zaszumienia [%]</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c33"><span class="c13 c36 c47">test_acc</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c33"><span class="c13 c36 c47">test_se</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c33"><span class="c13 c36 c47">test_sq</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c33"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c86"><td class="c76" colspan="1" rowspan="1"><p class="c33"><span class="c11">0</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.567</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.565</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.570</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.567</span></p></td></tr><tr class="c84"><td class="c76" colspan="1" rowspan="1"><p class="c33"><span class="c11">1</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.561</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.537</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.592</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.565</span></p></td></tr><tr class="c101"><td class="c76" colspan="1" rowspan="1"><p class="c33"><span class="c11">5</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.573</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.601</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.536</span></p></td><td class="c41" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.568</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Najlepsze wyniki osi&#261;gn&#261;&#322; model z poziomem zaszumienia na poziomie 5%.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 5. Czas inferencji, wymagania pami&#281;ciowe oraz rozmiar modelu dla modelu odniesienia.</span></p><a id="t.dc7260403f7827fb5617feac53e9f3ed3ce49689"></a><a id="t.4"></a><table class="c85"><tr class="c21"><td class="c57" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba parametr&oacute;w</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c44"><span class="c11">Rozmiar modelu [MB]</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c44"><span class="c11">Czas inferencji CPU</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c44"><span class="c11">Czas inferencji GPU</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c44"><span class="c11">Zaj&#281;to&#347;&#263; VRAM (batchsize 32) </span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c44"><span class="c11">Czas uczenia pojedynczej epoki</span></p></td></tr><tr class="c21"><td class="c57" colspan="1" rowspan="1"><p class="c14"><span class="c11">711705</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">2.715</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">mean:</span></p><p class="c14"><span class="c11">4.89 ms</span></p><p class="c14"><span class="c11">std:</span></p><p class="c14"><span class="c11">1.44 ms</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">mean:</span></p><p class="c14"><span class="c11">1.03 ms</span></p><p class="c14"><span class="c11">std:</span></p><p class="c14"><span class="c11">0.26 ms</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">~1450 MB</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c11">~ 7.00 sekund</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="5"><li class="c4 c52 li-bullet-0"><span class="c23 c13">ETAP V - Upraszczanie modelu</span></li></ol><p class="c4 c25"><span class="c23 c13"></span></p><p class="c4"><span class="c31 c13">Podczas treningu bazowego modelu dla 4 warstw zauwa&#380;alne by&#322;o du&#380;e przetrenowanie. W celu zmniejszenia rozmiaru modelu oraz ograniczenia zjawiska przetrenowania podj&#281;to pr&oacute;by uproszczenia modelu. Zastosowano:</span></p><p class="c26 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_ig4j23ubbon1-0 start" start="1"><li class="c26 c52 li-bullet-0"><span class="c31 c13">Usuni&#281;cie 4 warstw ResNet przed treningiem.</span></li></ol><p class="c26"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 228.00px;"><img alt="" src="images/image29.png" style="width: 601.70px; height: 228.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c14 c53 c95"><span>Rys. 3. Diagram przedstawiaj&#261;cy zmodyfikowan&#261; architektur&#281; modelu LungAttn </span><span><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?RsfQcK&amp;sa=D&amp;source=editors&amp;ust=1700747230291782&amp;usg=AOvVaw3-QChkHkXj3TRA939e9K8F">[1]</a></span><span class="c31 c13">.</span></p><p class="c4 c82 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Po usuni&#281;ciu 4 warstw ResNet i dostosowaniu modelu do nowego zadania zosta&#322;y ponownie przeprowadzone testy. Na poni&#380;szym wykresie zosta&#322; zaprezentowany przebieg treningu i ewaluacji nowego modelu. Hiperparametry by&#322;y takie same jak podczas uczenia modelu odniesienia.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 469.33px;"><img alt="" src="images/image30.png" style="width: 601.70px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c53"><span class="c31 c13">Rys. 4. Wykres przedstawiaj&#261;cy trening dla zmodyfikowanego modelu dla 2 klas.</span></p><p class="c7"><span class="c13 c31"></span></p><p class="c16"><span class="c31 c13">Na wykresie mo&#380;na zauwa&#380;y&#263;, &#380;e uproszczenie architektury modelu pomog&#322;o w zapobiegni&#281;ciu overfittingowi. &nbsp;Dodatkowo uda&#322;o si&#281; si&#281; polepszy&#263; dok&#322;adno&#347;ci do 61%.</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c31 c13">Tabela 6. Wyniki dla modelu z 4 usuni&#281;tymi warstwami. </span></p><a id="t.ea3b1058034de30ba9a011810490f9285d5769fe"></a><a id="t.5"></a><table class="c37"><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c33 c53"><span class="c36">Poziom zaszumienia [%]</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_acc</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_se</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_sq</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">0</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c44"><span class="c11">0.610</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c44"><span class="c11">0.741</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c44"><span class="c11">0.437</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c44"><span class="c11">0.589</span></p></td></tr></table><p class="c7"><span class="c31 c13"></span></p><p class="c4 c82 c25"><span class="c23 c13"></span></p><ol class="c50 lst-kix_ig4j23ubbon1-0" start="2"><li class="c26 c52 li-bullet-0"><span class="c31 c13">Przerzedzanie modelu</span></li></ol><p class="c9"><span class="c31 c13"></span></p><p class="c4"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kolejnym uproszczeniem, kt&oacute;re zastosowano by&#322;o przerzedzanie modelu. Wykorzystano przerzedzanie w czasie treningu w scenariuszu </span><span class="c62">trenuj-&gt;upraszczaj-&gt;dodawaj</span><span class="c31 c13">. Wybrano przerzedzanie w trakcie treningu, poniewa&#380; wcze&#347;niejsze etapy wskazywa&#322;y, &#380;e model si&#281; przetrenowuje, a pruning mo&#380;na wykorzysta&#263; jako dodatkow&#261; regularyzacj&#281;. Wykorzystano przerzedzanie ustrukturyzowane, polegaj&#261;ce na usuwaniu ca&#322;ych filtr&oacute;w. Nast&#281;pnie przywracano te z usuni&#281;tych po&#322;&#261;cze&#324;, kt&oacute;re mia&#322;y najwi&#281;ksz&#261; wag&#281;. W ten spos&oacute;b uzyskano kombinacj&#281; przerzedzania ustrukturyzowanego i nieustrukturyzowanego. Podczas projektowania tego sposobu przerzedzania wzi&#281;to pod uwag&#281; dwa czynniki istotne w rozwa&#380;anym problemie:</span></p><ol class="c50 lst-kix_85df5j8my8m6-0 start" start="1"><li class="c4 c52 li-bullet-0"><span class="c31 c13">wytrenowany model powinien by&#263; wykorzystywany na urz&#261;dzeniach o ograniczonej mocy obliczeniowej -&gt; usuwanie ca&#322;ych filtr&oacute;w pozwala zmniejszy&#263; wymagania obliczeniowe</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">ze wzgl&#281;du na wyst&#281;puj&#261;ce zjawisko przetrenowania wykorzystano dodawanie pojedynczych po&#322;&#261;cze&#324; do usuni&#281;tych filtr&oacute;w, aby w efekcie ograniczy&#263; ca&#322;kowit&#261; liczb&#281; po&#322;&#261;cze&#324; (zak&#322;ada si&#281;, &#380;e w kolejnych iteracjach usuwane s&#261; r&oacute;&#380;ne filtry).</span></li></ol><p class="c4"><span class="c31 c13">Po treningu usuni&#281;to za&#322;o&#380;ony odsetek filtr&oacute;w, tak aby ostateczny model by&#322; rzeczywi&#347;cie przerzedzony w spos&oacute;b ustrukturyzowany.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Do implementacji przerzedzania wykorzystano modu&#322; </span><span class="c45">torch.nn.utils.prune </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?NzFECV&amp;sa=D&amp;source=editors&amp;ust=1700747230296953&amp;usg=AOvVaw3OYtifoI7DyBGAac5PyOHI">[9]</a></span><span class="c45">&nbsp;</span><span>z biblioteki PyTorch. Do realizacji przerzedzania strukturalnego wykorzystano funkcj&#281; ln_structured </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?g6rMmF&amp;sa=D&amp;source=editors&amp;ust=1700747230297592&amp;usg=AOvVaw3BJCvAdpepgNJO4xuafeNN">[10]</a></span><span>. Funkcja ta okre&#347;la </span><span class="c45">mask&#281; przerzedzania</span><span>&nbsp;(ang. pruning mask) </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7RxTYK&amp;sa=D&amp;source=editors&amp;ust=1700747230298193&amp;usg=AOvVaw19Bk9BcNruHGfZXQtITdZk">[6</a></span><span>] na podstawie normy tensora wag wzd&#322;u&#380; okre&#347;lonego wymiaru. Funkcj&#281; t&#261; wykorzystano w ten spos&oacute;b, aby zerowa&#322;a okre&#347;lony odsetek filtr&oacute;w w oparciu o norm&#281; L2. Dodatkowo przerzedzano warstwy w pe&#322;ni po&#322;&#261;czone z wykorzystaniem funkcji</span><span>&nbsp;l1_unstructured()</span><span>&nbsp;.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c13 c48 c47">ZASTOSOWANIE PRZERZEDZANIA</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4 c22"><span class="c10">for </span><span class="c2">name</span><span class="c10">, </span><span class="c2">module </span><span class="c10">in </span><span class="c2 c13">model.named_modules():</span></p><p class="c4 c22"><span class="c2">&nbsp; &nbsp;</span><span class="c10">if </span><span class="c30">isinstance</span><span class="c2">(module</span><span class="c10">, </span><span class="c2 c13">torch.nn.Conv2d):</span></p><p class="c4 c22"><span class="c2">&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prune.ln_structured(module</span><span class="c10">,</span><span class="c42">name</span><span class="c2">=</span><span class="c81">&quot;weight&quot;</span><span class="c10">, </span><span class="c42">amount</span><span class="c2">=args.prunning_amount</span><span class="c10">, </span><span class="c42">n</span><span class="c2">=</span><span class="c75">2</span><span class="c10">, </span><span class="c42">dim</span><span class="c2">=</span><span class="c75">0</span><span class="c2 c13">)</span></p><p class="c4 c22"><span class="c2">&nbsp; &nbsp;</span><span class="c10">if </span><span class="c30">isinstance</span><span class="c2">(module</span><span class="c10">, </span><span class="c2 c13">torch.nn.Linear):</span></p><p class="c4 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;prune.l1_unstructured(module</span><span class="c10">, </span><span class="c42">name</span><span class="c2">=</span><span class="c81">&quot;weight&quot;</span><span class="c10">, </span><span class="c42">amount</span><span class="c2">=</span><span class="c75">0.4</span><span class="c2 c13">)</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Nast&#281;pnie na podstawie klasy </span><span class="c45">BasePruningMethod </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?vSEhnV&amp;sa=D&amp;source=editors&amp;ust=1700747230301768&amp;usg=AOvVaw2oL7uiteoDJsGYpAPW6QdX">[11]</a></span><span class="c45">&nbsp;</span><span>zbudowano klas&#281; </span><span class="c45">Regrowth </span><span>s&#322;u&#380;&#261;c&#261; do dodawania po&#322;&#261;cze&#324; po przerzedzaniu. Zdefiniowano r&oacute;wnie&#380; funkcj&#281; </span><span class="c45">regrowth_unstructured()</span><span>, kt&oacute;ra dodaje po&#322;&#261;czenia do modu&#322;u podanego jako argument. Zbudowana klasa pozwala dodawa&#263; po&#322;&#261;czenia losowe (opcja </span><span class="c45">random</span><span>) lub te, kt&oacute;re przed przerzedzaniem posiada&#322;y najwi&#281;ksz&#261; wag&#281; (opcja </span><span class="c45">magnitude</span><span class="c31 c13">).</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c13 c47 c48">KLASA REGROWTH</span></p><p class="c26 c22"><span class="c10">class </span><span class="c2 c13">Regrowth(prune.BasePruningMethod):</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp;</span><span class="c56 c64 c45 c73">&#39;&#39;&#39;Regrow pruned parameters</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp;regrowth method specified in constructor should be</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp;- &quot;random&quot; for regrowing random connections</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp; or</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp;- &quot;magnitude&quot; for regrowing important connections</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp;&#39;&#39;&#39;</span></p><p class="c26 c22 c25"><span class="c56 c64 c45 c73"></span></p><p class="c26 c22"><span class="c45 c56">&nbsp; &nbsp;</span><span class="c2">PRUNING_TYPE = </span><span class="c81 c13">&#39;global&#39;</span></p><p class="c26 c22 c25"><span class="c81 c13"></span></p><p class="c26 c22"><span class="c81">&nbsp; &nbsp;</span><span class="c10">def </span><span class="c83">__init__</span><span class="c2">(</span><span class="c27">self</span><span class="c10 c13">,</span></p><p class="c26 c22"><span class="c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2">regrowth_method</span><span class="c10 c13">,</span></p><p class="c26 c22"><span class="c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2">amount</span><span class="c10 c13">,</span></p><p class="c26 c22"><span class="c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2">seed=</span><span class="c75">5000</span><span class="c2 c13">):</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c56 c64 c45 c73">&#39;&#39;&#39;Regrowth class constructor</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;args: regrowth_method -&gt; &quot;random&quot; or &quot;magnitude&quot;</span></p><p class="c26 c22"><span class="c56 c64 c45 c73">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;amount of connections to be regrown (0, 1)&#39;&#39;&#39;</span></p><p class="c26 c22 c25"><span class="c56 c64 c45 c73"></span></p><p class="c26 c22"><span class="c56 c45">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c27">self</span><span class="c2 c13">.regrowth_method = regrowth_method</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c27">self</span><span class="c2 c13">.amount = amount</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c27">self</span><span class="c2 c13">.seed = seed</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp;</span><span class="c10">def </span><span class="c40">compute_mask</span><span class="c2">(</span><span class="c27">self</span><span class="c10">, </span><span class="c2">t</span><span class="c10">, </span><span class="c2 c13">default_mask):</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp;mask = default_mask.clone()</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c59 c13"># calculate complementary to given mask e.g. [0, 0, 1, 0] -&gt; [1, 1, 0, 1]</span></p><p class="c26 c22"><span class="c59">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c2">complement_mask = torch.logical_xor(mask</span><span class="c10">, </span><span class="c2 c13">torch.ones_like(mask)).type(mask.type())</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;num_pruned = </span><span class="c30">int</span><span class="c2 c13">(torch.sum(complement_mask))</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;num_to_regrow = </span><span class="c30">int</span><span class="c2">(</span><span class="c27">self</span><span class="c2 c13">.amount * num_pruned)</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp;pruned_weight_indices = torch.nonzero(complement_mask)</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c10">if </span><span class="c27">self</span><span class="c2">.regrowth_method == </span><span class="c81">&#39;random&#39;</span><span class="c2 c13">:</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;indices_of_chosen_ones = np.random.choice(num_pruned</span><span class="c10">, </span><span class="c42">size</span><span class="c2">=num_to_regrow</span><span class="c10">, </span><span class="c42">replace</span><span class="c2">=</span><span class="c10">False</span><span class="c2 c13">)</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;chosen_ones = pruned_weight_indices[indices_of_chosen_ones]</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mask[chosen_ones] = </span><span class="c75 c13">1.</span></p><p class="c26 c22"><span class="c75">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c10">if </span><span class="c27">self</span><span class="c2">.regrowth_method == </span><span class="c81">&#39;magnitude&#39;</span><span class="c2 c13">:</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pruned_weights_mask = complement_mask - mask * torch.ones_like(mask) * </span><span class="c30">float</span><span class="c2">(</span><span class="c81">&#39;inf&#39;</span><span class="c2 c13">)</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pruned_weights = t * pruned_weights_mask</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pruned_weights_flat = pruned_weights.flatten()</span></p><p class="c26 c22"><span class="c2 c13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mask_flat = mask.flatten()</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;most_important = torch.topk(pruned_weights_flat</span><span class="c10">, </span><span class="c2 c13">num_to_regrow).indices</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mask_flat[most_important] = </span><span class="c75 c13">1.</span></p><p class="c26 c22"><span class="c75">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c2">mask = torch.reshape(mask_flat</span><span class="c10">, </span><span class="c30">tuple</span><span class="c2 c13">(mask.size()))</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c10">return </span><span class="c2 c13">mask</span></p><p class="c26 c22 c25"><span class="c2 c13"></span></p><p class="c26 c22"><span class="c10">def </span><span class="c40">regrowth_unstructured</span><span class="c2">(module</span><span class="c10">, </span><span class="c2">name</span><span class="c10">, </span><span class="c2">regrowth_method</span><span class="c10">, </span><span class="c2">amount</span><span class="c10">, </span><span class="c2">seed=</span><span class="c75">5000</span><span class="c2 c13">):</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp;kwargs = {</span><span class="c81">&#39;regrowth_method&#39;</span><span class="c2">: regrowth_method</span><span class="c10 c13">,</span></p><p class="c26 c22"><span class="c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c81">&#39;amount&#39;</span><span class="c2">: amount</span><span class="c10 c13">,</span></p><p class="c26 c22"><span class="c10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c81">&#39;seed&#39;</span><span class="c2 c13">: seed}</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp;Regrowth.apply(module</span><span class="c10">, </span><span class="c2">name</span><span class="c10">, </span><span class="c2 c13">**kwargs)</span></p><p class="c26 c22 c25"><span class="c10 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c13 c48 c47">ZASTOSOWANIE DODAWANIA PO&#321;&#260;CZE&#323;</span></p><p class="c26 c22"><span class="c10">if </span><span class="c2">epoch &gt; </span><span class="c75">0 </span><span class="c10">and </span><span class="c2 c13">args.use_regrowth:</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp;</span><span class="c10">for </span><span class="c2">_</span><span class="c10">, </span><span class="c2">module </span><span class="c10">in </span><span class="c2 c13">net.named_modules():</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c10">if </span><span class="c30">isinstance</span><span class="c2">(module</span><span class="c10">, </span><span class="c2 c13">torch.nn.Conv2d):</span></p><p class="c26 c22"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;regrowth_unstructured(module</span><span class="c10">, </span><span class="c42">name</span><span class="c2">=</span><span class="c81">&#39;weight&#39;</span><span class="c10">, </span><span class="c42">regrowth_method</span><span class="c2">=</span><span class="c81">&#39;magnitude&#39;</span><span class="c10">, </span><span class="c42">amount</span><span class="c2">=</span><span class="c75">0.5</span><span class="c2 c13">)</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Hiperparametry:</span></p><p class="c4"><span>Aby umo&#380;liwi&#263; dynamiczne zmiany stopnia przerzedzenia modelu wprowadzono wsp&oacute;&#322;czynnik </span><span class="c45">regrowth_decay</span><span class="c31 c13">&nbsp;zmniejszaj&#261;cy odsetek dodawanych po&#322;&#261;cze&#324; w kolejnych epokach. Liczb&#281; dodawanych po&#322;&#261;cze&#324; zmniejszano zgodnie z poni&#380;szym r&oacute;wnaniem. </span></p><p class="c4 c22"><span class="c2 c13">regrowth_amount = regrowth_amount * args.regrowth_decay</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Parametry przerzedzania przedstawiono w tabeli 7. Og&oacute;lne hiperparametry by&#322;y takie same jak podczas uczenia modelu odniesienia. Hiperparametry te przedstawiono wcze&#347;niej w tabeli 3.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Tabela 7. Parametry metody przerzedzania.</span></p><a id="t.7c2754c68c6b3b2d7af8cd33503425bbad04d6a8"></a><a id="t.6"></a><table class="c37"><tr class="c21"><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">Stopie&#324; przerzedzenia warstw splotowych (ustrukturyzowane)</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">Stopie&#324; przerzedzenia warstw w pe&#322;ni po&#322;&#261;czonych (nieustrukturyzowane)</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">Odsetek dodawanych po&#322;&#261;cze&#324; (regrowth amount)</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c14"><span class="c11">Wsp&oacute;&#322;czynnik zmniejszaj&#261;cy dodawany odsetek po&#322;&#261;cze&#324; (regrowth decay)</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c14"><span class="c11">Typ procedury dodawania po&#322;&#261;cze&#324;</span></p></td></tr><tr class="c21"><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.3</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.4</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.8</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c14"><span class="c11">0.98</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c14"><span class="c11">magnitude</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Opis treningu:</span></p><p class="c4"><span class="c31 c13">Na pocz&#261;tku przeprowadzono trening, w kt&oacute;rym iteracyjnie dodawano i usuwano po&#322;&#261;czenia. Po zako&#324;czeniu treningu dokonano przerzedzania ustrukturyzowanego, w kt&oacute;rym usuni&#281;to &nbsp;pewien odsetek filtr&oacute;w w warstwach splotowych. W tabeli przedstawiono metryki jako&#347;ci dzia&#322;ania modelu oraz czas inferencji dla r&oacute;&#380;nego stopnia przerzedzenia ustrukturyzowanego.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Wyniki:</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Krzywe uczenia przedstawiono na rysunku 5. Wida&#263;, &#380;e po oko&#322;o 50 epoce nast&#281;puje przetrenowanie modelu.</span></p><p class="c26"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 366.67px;"><img alt="" src="images/image32.png" style="width: 601.70px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c31 c13">Rys. 5. Krzywe uczenia dla modelu z przerzedzaniem.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c4"><span>Wyniki dla r&oacute;&#380;nego stopnia przerzedzenia ustrukturyzowanego po treningu przedstawiono w tabeli 8. Sumaryczny stopie&#324; przerzedzenia oznacza ca&#322;kowity odsetek po&#322;&#261;cze&#324; usuni&#281;tych w czasie treningu wraz z po&#322;&#261;czeniami usuni&#281;tymi po treningu poprzez przerzedzanie ustrukturyzowane. Analizuj&#261;c wyniki mo&#380;na zauwa&#380;y&#263;, &#380;e metryka </span><span class="c45">score</span><span>&nbsp;spada nieznacznie dla przerzedze&#324; 0.1, 0.2, 0.3. Dla wi&#281;kszych przerzedze&#324; jako&#347;&#263; zaczyna stopniowo spada&#263;. Dla przerzedzenia 0.8 metryka </span><span class="c45">score</span><span class="c31 c13">&nbsp;oraz dok&#322;adno&#347;&#263; spadaj&#261; ju&#380; znacz&#261;co do warto&#347;ci odpowiednio 0.5336 oraz 0.4983.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 8. Metryki dok&#322;adno&#347;ci dla r&oacute;&#380;nego stopnia przerzedzenia ustrukturyzowanego po treningu.</span></p><a id="t.9d88a20c12288609aced3e9a0388ada04786ac98"></a><a id="t.7"></a><table class="c37"><tr class="c21"><td class="c78" colspan="1" rowspan="1"><p class="c14"><span class="c11">Stopie&#324; przerzedzenia ustrukturyzowanego </span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c14"><span class="c11">Sumaryczny stopie&#324; przerzedzenia (nieustrukturyzowane + ustrykturyzowane)</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_acc</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_se</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_sq</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c21"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">Model odniesienia</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">-</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.565</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.570</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td></tr><tr class="c21"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.0</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">55.21 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6030</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5402</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6873</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6138</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.1</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">59.22 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6005</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5370</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6858</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6113</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.2</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">63.89 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5954</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5130</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.7060</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6095</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.3</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">68.42 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5653</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4123</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.7706</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5914</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">73.00 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5911</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5820</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6032</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5926</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">77.06 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5940</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6947</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4588</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5768</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">81.67 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5715</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5871</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5506</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5688</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.7</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">86.34 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5522</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4845</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6432</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5638</span></p></td></tr><tr class="c32"><td class="c78" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.8</span></p></td><td class="c79" colspan="1" rowspan="1"><p class="c5"><span class="c11">90.80 %</span></p></td><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4983</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.2932</span></p></td><td class="c12" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.7750</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5336</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Domy&#347;lnie przerzedzanie w bibliotece PyTorch nie przynosi korzy&#347;ci dotycz&#261;cych zmniejszenia rozmiaru modelu czy czasu inferencji. Taki wniosek mo&#380;na wyci&#261;gn&#261;&#263; analizuj&#261;c wyniki przedstawione w tabeli 9. Czas inferencji na CPU zmienia si&#281;, ale mo&#380;e to zale&#380;e&#263; nie tylko od stopnia przerzedzenia, ale r&oacute;wnie&#380; od chwilowego obci&#261;&#380;enia procesora.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 9. Czas inferencji, wymagania pami&#281;ciowe oraz rozmiar modelu dla r&oacute;&#380;nych stopni przerzedze&#324;.</span></p><a id="t.95201439246700ee24911a07a9000aa6d5fc32fb"></a><a id="t.8"></a><table class="c37"><tr class="c94"><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">Stopie&#324; przerzedzenia ustrukturyzowanego </span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba parametr&oacute;w</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c44"><span class="c11">Rozmiar modelu [MB]</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c44"><span class="c11">Czas inferencji CPU</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c44"><span class="c11">Czas inferencji GPU</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c44"><span class="c11">Zaj&#281;to&#347;&#263; VRAM</span></p><p class="c44"><span class="c11">(batchsize 32) </span></p></td></tr><tr class="c21"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">Model odniesienia</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">4.89 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">1.44 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.03 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.26 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c21"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.0</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">4.67 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.05 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.16 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.07 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.1</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.16 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.16 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.2</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">4.68 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.31 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.16 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.11 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.3</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.17 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.24 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.07 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.31 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.42 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.26 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">4.62 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.07 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.17 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.04 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.21 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.12 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.22 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.10 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.7</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.15 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">0.12 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.26 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr><tr class="c32"><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.8</span></p></td><td class="c77" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.19 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.06 ms</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.17 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.04 ms</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c5"><span class="c11">~1450 MB</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_85df5j8my8m6-0" start="3"><li class="c26 c52 li-bullet-0"><span class="c31 c13">Algorytm RigL </span></li></ol><p class="c26 c25"><span class="c31 c13"></span></p><p class="c4"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kolejnym zastosowanym algorytmem by&#322; algorytm RigL </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?4bI6DZ&amp;sa=D&amp;source=editors&amp;ust=1700747230357436&amp;usg=AOvVaw0Fquu-r99c0nzh19fF5hLy">[12]</a></span><span>. Algorytm ten polega na znacznym przerzedzeniu modelu przed treningiem. Przerzedzony model jest nast&#281;pnie trenowany. Z modelu cyklicznie, co pewn&#261; liczb&#281; krok&oacute;w treningowych </span><img src="images/image1.png"><span>, jest usuwany i dodawany pewien odsetek po&#322;&#261;cze&#324;. Struktura modelu zmienia si&#281; dynamicznie w czasie treningu. Algorytm RigL przedstawiono w poni&#380;szej tabeli 10. Parametr </span><img src="images/image1.png"><span>&nbsp;okre&#347;la, co jak&#261; liczb&#281; krok&oacute;w struktura modelu jest zmieniana. Parametr </span><img src="images/image2.png"><span>&nbsp;oznacza numer kroku, po kt&oacute;rym struktura modelu nie ulega ju&#380; zmianom. Parametry </span><img src="images/image3.png"><span>, </span><img src="images/image4.png"><span>&nbsp;okre&#347;laj&#261; liczb&#281; po&#322;&#261;cze&#324;, kt&oacute;re s&#261; usuwane i dodawane w czasie zmiany struktury sieci. Do dynamicznej zmiany liczby dodawanych i usuwanych po&#322;&#261;cze&#324; zastosowano funkcj&#281;, kt&oacute;r&#261; proponuj&#261; autorzy artyku&#322;u RigL </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?ECnM1a&amp;sa=D&amp;source=editors&amp;ust=1700747230366883&amp;usg=AOvVaw3PUYWFHPUsUbPd7DrP6K9e">[12]</a></span><span class="c31 c13">&nbsp;(1).</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c33 c53"><img src="images/image5.png"><span class="c13 c47 c98">&nbsp;(1)</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Autorzy pracy proponuj&#261; r&oacute;wnie&#380; r&oacute;&#380;ne strategie do definiowania stopnia przerzedzenia kolejnych warstw </span><img src="images/image6.png"><span>. Podczas test&oacute;w na potrzeby projektu zastosowano jednakowe przerzedzenie wszystkich warstw </span><img src="images/image7.png"><span>&nbsp;Funkcja </span><img src="images/image8.png"><span>&nbsp;jest kryterium usuwania po&#322;&#261;cze&#324;. Usuwa ona </span><img src="images/image9.png"><span>&nbsp;po&#322;&#261;cze&#324; o najmniejszych wagach. Funkcja </span><img src="images/image10.png"><span class="c31 c13">&nbsp;okre&#347;la natomiast, kt&oacute;re po&#322;&#261;czenia powinny by&#263; dodane do modelu. Wskazuje ona na te po&#322;&#261;czenia, dla kt&oacute;rych chwilowy gradient przyjmuje najwi&#281;ksz&#261; warto&#347;&#263;. </span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Tabela 10. Algorytm RigL</span></p><a id="t.eb8a00ee687e931030126d8cb792b79d5fae612a"></a><a id="t.9"></a><table class="c37"><tr class="c21"><td class="c54" colspan="1" rowspan="1"><p class="c14"><span>Algorytm RigL </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?wA6ltL&amp;sa=D&amp;source=editors&amp;ust=1700747230388959&amp;usg=AOvVaw13IIied2wxUmyabOvDIwku">[12]</a></span></p></td></tr><tr class="c21"><td class="c54" colspan="1" rowspan="1"><p class="c14"><span class="c62">dane wej&#347;ciowe</span><span>: Model </span><img src="images/image11.png"><span>, zbi&oacute;r danych </span><img src="images/image12.png"><span>, przerzedzenie warstw </span><img src="images/image13.png"><span>, plan przerzedzania wyra&#380;ony parametrami </span><img src="images/image1.png"><span>, </span><img src="images/image2.png"><span>, </span><img src="images/image3.png"><span>, </span><img src="images/image4.png"></p><p class="c14"><span class="c13 c48 c47">algorytm:</span></p><p class="c14"><span>losowe przerzedzenie wag </span><img src="images/image14.png"><span>ze stopniem </span><img src="images/image6.png"><span class="c31 c13">&nbsp;dla ka&#380;dej warstwy</span></p><p class="c14"><span class="c62">dla </span><span>kolejnych krok&oacute;w treningu </span><span class="c31 c64 c45 c73">t:</span></p><p class="c14"><span class="c45">&nbsp; &nbsp; &nbsp; </span><span>pobierz mini-batch </span><img src="images/image15.png"><span>&nbsp;ze zbioru </span><img src="images/image12.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp;oblicz funkcj&#281; straty </span><img src="images/image16.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp;</span><span class="c62">je&#347;li </span><img src="images/image17.png"><span>&nbsp;modulo </span><img src="images/image1.png"><span>&nbsp;== 0 oraz </span><span class="c62">&nbsp;</span><img src="images/image17.png"><span>&nbsp; &lt; </span><img src="images/image18.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c62">dla &nbsp;</span><span class="c31 c13">kolejnych warstw l:</span></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><img src="images/image19.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><img src="images/image20.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><img src="images/image21.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><img src="images/image22.png"><span>&nbsp;usu&#324; po&#322;&#261;czenia </span><img src="images/image23.png"><span>&nbsp; oraz dodaj po&#322;&#261;czenia </span><img src="images/image24.png"></p><p class="c14"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c13 c48 c47">koniec p&#281;tli</span></p><p class="c14"><span class="c13 c48 c47">&nbsp; &nbsp; &nbsp;w przeciwnym razie:</span></p><p class="c14"><span class="c62">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c31 c13">aktualizuj wagi</span></p><p class="c14"><span>&nbsp; &nbsp; &nbsp;</span><span class="c13 c48 c47">koniec dyrektywy je&#347;li</span></p><p class="c14"><span class="c13 c48 c47">koniec p&#281;tli</span></p></td></tr></table><p class="c4 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Implementacja:</span></p><p class="c4"><span>Algorytm zaimplementowano troch&#281; inaczej ni&#380; oryginalny algorytm RigL. Aktualizacji struktury dokonywano nie co pewn&#261; liczb&#281; krok&oacute;w treningu, ale cyklicznie co </span><img src="images/image1.png"><span class="c31 c13">&nbsp;epizod&oacute;w.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Hiperparametry:</span></p><p class="c4"><span class="c31 c13">Og&oacute;lne hiperparametry by&#322;y takie same jak podczas uczenia modelu odniesienia. Parametry metody RigL przedstawiono w tabeli 11. </span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Tabela 10. Parametry metody RigL.</span></p><a id="t.ad0d1d72156b0e4003ab17e1cb25b78760b898ed"></a><a id="t.10"></a><table class="c85"><tr class="c21"><td class="c60" colspan="1" rowspan="1"><p class="c14"><span class="c58">Pocz&#261;tkowe przerzedzenie modelu </span><img src="images/image25.png"></p></td><td class="c60" colspan="1" rowspan="1"><p class="c14"><img src="images/image1.png"><span class="c11">&nbsp;(co ile epizod&oacute;w nast&#281;puje zmiana struktury)</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c14"><img src="images/image2.png"><span class="c11">&nbsp;(epoka, po kt&oacute;rej struktura modelu nie ulega zmianie) </span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c14"><img src="images/image3.png"><span class="c11">&nbsp;- wsp&oacute;&#322;czynnik zmniejszaj&#261;cy liczb&#281; dodawanych i usuwanych po&#322;&#261;cze&#324;</span></p></td></tr><tr class="c21"><td class="c60" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.8</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c5"><span class="c11">5</span></p></td><td class="c89" colspan="1" rowspan="1"><p class="c5"><span class="c11">60</span></p></td><td class="c57" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.3</span></p></td></tr></table><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Wyniki:</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Analizuj&#261;c wyniki przedstawione w modelu wida&#263;, &#380;e model uczony metod&#261; RigL uzyska&#322; najlepsze rezultaty ze wszystkich przetestowanych dot&#261;d metod. Dok&#322;adno&#347;&#263; testowa wynosi&#322;a 0.6295, natomiast metryka </span><span class="c45">score </span><span class="c31 c13">uzyska&#322;a warto&#347;&#263; 0.6251. W kontek&#347;cie czasu inferencji oraz rozmiaru modelu nie uzyskano poprawy.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 11. Wyniki uzyskane z wykorzystaniem algorytmu RigL.</span></p><a id="t.0e7e72f1e373cfccddc2e3d060a911ff6439a222"></a><a id="t.11"></a><table class="c37"><tr class="c21"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c11">Model</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba parametr&oacute;w</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c11">Rozmiar [MB]</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji CPU</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji GPU</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_acc</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_se</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_sq</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c80"><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">Model odniesienia</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">4.89 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">1.44 ms</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.03 ms</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.26 ms</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.565</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.570</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td></tr><tr class="c80"><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">Model binarny uczony przez RigL</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.70 ms </span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.93 ms</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.30ms </span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.17 ms</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c5"><span class="c13 c36 c47">0.629</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c5"><span class="c13 c36 c47">0.655</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c13 c36 c47">0.594</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c13 c36 c47">0.625</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="6"><li class="c4 c52 li-bullet-0"><span class="c23 c13">ETAP VI - Dodatkowe optymalizacje modelu</span></li></ol><p class="c4 c25"><span class="c23 c13"></span></p><ol class="c50 lst-kix_cqit75b193hp-0 start" start="1"><li class="c4 c52 li-bullet-0"><span class="c31 c13">Destylacja wiedzy </span></li></ol><p class="c4 c25 c82"><span class="c31 c13"></span></p><p class="c4 c17"><span class="c31 c13">W celu wprowadzenia kolejnych optymalizacji zastosowano destylacj&#281; wiedzy, aby wytrenowa&#263; model o mniejszych rozmiarach, kt&oacute;ry osi&#261;ga&#322; by wyniki podobne do uzyskanych przez algorytm RigL. Architektury nauczyciela oraz ucznia przedstawiono na rysunku 6. Model nauczyciela inicjalizowany by&#322; wagami wytrenowanymi przez algorytm RigL. Rozmiar ucznia zredukowano poprzez zmniejszenie liczby kana&#322;&oacute;w wej&#347;ciowych oraz wyj&#347;ciowych w kolejnych warstwach do 32 kana&#322;&oacute;w. Funkcja straty sk&#322;ada&#322;a si&#281; z dw&oacute;ch wa&#380;onych cz&#322;on&oacute;w:</span></p><ul class="c50 lst-kix_xpxvaauxcm5m-0 start"><li class="c4 c52 li-bullet-0"><span>BCELoss() </span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?QK2s9l&amp;sa=D&amp;source=editors&amp;ust=1700747230455710&amp;usg=AOvVaw1qnz3SbApVvB8_-a4Yvu69">[8]</a></span><span class="c31 c13">&nbsp;pomi&#281;dzy etykietami ground truth, a wyj&#347;ciem ucznia,</span></li><li class="c4 c52 li-bullet-0"><span class="c31 c13">BCELoss() pomi&#281;dzy wyj&#347;ciem nauczyciela, a wyj&#347;ciem ucznia.</span></li></ul><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Funkcja straty L by&#322;a sum&#261; powy&#380;szych cz&#322;on&oacute;w, wa&#380;on&#261; przez wag&#281; </span><img src="images/image26.png"><span class="c31 c13">&nbsp;(2).</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c33 c53"><img src="images/image27.png"><span>(2)</span></p><p class="c4"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 316.00px;"><img alt="" src="images/image28.png" style="width: 601.70px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c31 c13">Rys. 6. Architektury ucze&#324;/student podczas destylacji wiedzy.</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span>Destylacj&#281; zaimplementowano poprzez wprowadzenie odpowiedniej funkcji straty do p&#281;tli treningowej. Model nauczyciela wprowadzono do trybu ewaluacji poprzez metod&#281; </span><span class="c45">teacher.eval()</span><span class="c31 c13">. Fragment kodu w p&#281;tli treningowej przedstawiono poni&#380;ej. </span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4 c22"><span class="c59 c13"># get teacher outputs</span></p><p class="c4 c22"><span class="c10">with </span><span class="c2 c13">torch.no_grad():</span></p><p class="c4 c22"><span class="c2 c13">&nbsp; &nbsp;teacher_outputs = teacher(cat_stft)</span></p><p class="c4 c22 c25"><span class="c2 c13"></span></p><p class="c4 c22"><span class="c59 c13"># get student outputs</span></p><p class="c4 c22"><span class="c2 c13">student_outputs = student(cat_stft)</span></p><p class="c4 c22 c25"><span class="c2 c13"></span></p><p class="c4 c22"><span class="c59 c13"># calculate distillation_loss</span></p><p class="c4 c22"><span class="c2">distillation_loss = criterion(student_outputs</span><span class="c10">, </span><span class="c2 c13">teacher_outputs)</span></p><p class="c4 c22 c25"><span class="c2 c13"></span></p><p class="c4 c22"><span class="c59 c13"># label loss</span></p><p class="c4 c22"><span class="c2 c13">labels = labels.type_as(student_outputs)</span></p><p class="c4 c22"><span class="c2">label_loss = criterion(student_outputs</span><span class="c10">, </span><span class="c2 c13">labels)</span></p><p class="c4 c22 c25"><span class="c2 c13"></span></p><p class="c4 c22"><span class="c2">loss = args.distillation_weight * distillation_loss + (</span><span class="c75">1 </span><span class="c2 c13">- args.distillation_weight)*label_loss</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Parametry:</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Parametry destylacji przedstawiono w tabeli 12. Og&oacute;lne hiperparametry by&#322;y takie same jak podczas uczenia modelu odniesienia (tabela 3).</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Tabela 12. Parametry podczas procesu destylacji wiedzy.</span></p><a id="t.d5c188a2052e8ef12f8cd51a93cfae984a499fd8"></a><a id="t.12"></a><table class="c37"><tr class="c21"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c58">Waga funkcji straty </span><img src="images/image26.png"></p></td><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.4</span></p></td></tr><tr class="c72"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba kana&#322;&oacute;w ucznia</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c11">32</span></p></td></tr><tr class="c72"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba kana&#322;&oacute;w nauczyciela</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c11">64</span></p></td></tr><tr class="c72"><td class="c15" colspan="1" rowspan="1"><p class="c14"><span class="c11">Optymalizator</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c5"><span class="c11">SGD</span></p></td></tr></table><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Wyniki:</span></p><p class="c4 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">Wyniki oraz rozmiar i czas inferencji dla modelu nauczyciela i ucznia por&oacute;wnano w tabeli 13. Analizuj&#261;c wyniki zamieszczone w tabeli mo&#380;na zauwa&#380;y&#263;, &#380;e destylacja wiedzy pozwoli&#322;a znacz&#261;co zmniejszy&#263; rozmiar modelu, skr&oacute;ci&#263; czas inferencji. Dok&#322;adno&#347;&#263; modelu nieznacznie spad&#322;a. Czas treningu jednej epoki wynosi&#322; oko&#322;o 7 sekund. Warto stosowa&#263; zatem po&#322;&#261;czenie przerzedzania jako formy regularyzacji oraz destylacj&#281; wiedzy do zmniejszenia rozmiar&oacute;w i czasu inferencji.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Tabela 13. Por&oacute;wnanie wynik&oacute;w nauczyciela i ucznia.</span></p><a id="t.4f88300397adada221d5cdc30c19959ec838dc0c"></a><a id="t.13"></a><table class="c37"><tr class="c21"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c11">Model</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c11">Liczba parametr&oacute;w</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c11">Rozmiar [MB]</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji CPU</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c14"><span class="c11">Czas inferencji GPU</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_acc</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_se</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_sq</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c80"><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">Nauczyciel</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c5"><span class="c11">711705</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c5"><span class="c11">2.715</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">3.70 ms </span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.93 ms</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c11">1.30ms </span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.17 ms</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6295</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6555</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5947</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6251</span></p></td></tr><tr class="c32"><td class="c18" colspan="1" rowspan="1"><p class="c5"><span class="c11">Ucze&#324;</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c5"><span class="c11">187193</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c5"><span class="c13 c36 c47">0.714</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c13 c36 c47">2.71 ms </span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.12ms</span></p></td><td class="c71" colspan="1" rowspan="1"><p class="c5"><span class="c11">mean:</span></p><p class="c5"><span class="c36">0.94 ms</span><span class="c11">&nbsp;</span></p><p class="c5"><span class="c11">std:</span></p><p class="c5"><span class="c11">0.09ms</span></p></td><td class="c65" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6241</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6770</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.5531</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.6151</span></p></td></tr></table><p class="c26 c25"><span class="c31 c13"></span></p><p class="c4 c25"><span class="c31 c13"></span></p><ol class="c50 lst-kix_oigadj3gksiy-0" start="7"><li class="c4 c52 li-bullet-0"><span class="c23 c13">ETAP VII - Optymalizacja uczenia si&#281;</span></li></ol><p class="c16 c25"><span class="c31 c13"></span></p><p class="c4"><span class="c31 c13">W tym badaniu wykorzystano r&oacute;&#380;ne funkcje aktywacji i oraz augmentacj&#281; danych typu mixup. Parametr alpha &nbsp;jest u&#380;ywany do kontrolowania stopnia miksowania mi&#281;dzy dwiema pr&oacute;bkami danych, kt&oacute;re s&#261; &#322;&#261;czone w celu stworzenia nowej pr&oacute;bki danych. Wykorzystanie mixup&#39;u powinno pom&oacute;c w regularyzacji modelu.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c16"><span class="c31 c13">Tabela 14. Wyniki dla r&oacute;&#380;nych wariant&oacute;w optymalizacji treningu.</span></p><a id="t.b53c4206b22acce4dfb3d684059acf3ea43337bc"></a><a id="t.14"></a><table class="c37"><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c33 c53 c25"><span class="c11"></span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_acc</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_se</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_sq</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c44"><span class="c13 c36 c47">test_score</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">Model odniesienia</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.565</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.570</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c5"><span class="c11">0.567</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">mixup alpha=0.5 + ReLU</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.606</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.915</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.194</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.555</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">mixup alpha=0.5 + ReLU6</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.589</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.835</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.261</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.548</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">mixup alpha=1.0 + ReLU6</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.603</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.850</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.275</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.562</span></p></td></tr><tr class="c69"><td class="c76" colspan="1" rowspan="1"><p class="c44"><span class="c11">mixup alpha=1.0 + PReLU</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.591</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.685</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.466</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c33"><span class="c11">0.576</span></p></td></tr></table><p class="c7"><span class="c23 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c62">mixup alpha=0.5 + ReLU</span><span class="c31 c13">: Model osi&#261;gn&#261;&#322; akceptowaln&#261; dok&#322;adno&#347;&#263; (0.606) na zbiorze testowym, ale ma ni&#380;sz&#261; czu&#322;o&#347;&#263; (0.915) i specyficzno&#347;&#263; (0.194), co mo&#380;e oznacza&#263;, &#380;e jest bardziej skoncentrowany na jednym rodzaju b&#322;&#281;d&oacute;w.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c62">mixup alpha=0.5 + ReLU6</span><span class="c31 c13">: Wykorzystanie funkcji aktywacji ReLU6 zamiast ReLU nie przynios&#322;o oczekiwanych skutk&oacute;w. Dok&#322;adno&#347;&#263; predykcji jest mniejsza.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c62">mixup alpha=1.0 + ReLU6</span><span class="c31 c13">: Ten model osi&#261;gn&#261;&#322; podobn&#261; dok&#322;adno&#347;&#263; (0.603) jak pierwszy model mixup, ale ma wy&#380;sz&#261; czu&#322;o&#347;&#263; (0.850) i specyficzno&#347;&#263; (0.275). To mo&#380;e sugerowa&#263;, &#380;e zwi&#281;kszenie warto&#347;ci parametru alpha w mixup i zastosowanie funkcji aktywacji poprawi&#322;o zdolno&#347;&#263; modelu do rozpoznawania pozytywnych i negatywnych przypadk&oacute;w.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c62">mixup alpha=1.0 + PReLU</span><span class="c31 c13">: Ten model osi&#261;gn&#261;&#322; nieco ni&#380;sz&#261; dok&#322;adno&#347;&#263; (0.591) i czu&#322;o&#347;&#263; (0.685) i znacznie wy&#380;sz&#261; specyficzno&#347;&#263; (0.466). Stosowanie funkcji aktywacji PReLU nie przynios&#322;o znacz&#261;cej poprawy wydajno&#347;ci w por&oacute;wnaniu do ReLU6.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Dodanie augmentacji pomog&#322;o uzyska&#263; lepsze wyniki - ka&#380;dy rezultat jest lepszy od tego, gdzie nie wykorzystano augmentacji. Zmiana funkcji aktywacji nie przynios&#322;a oczekiwanych rezultat&oacute;w. W przypadku tej sieci zastosowanie ReLU6 lub PReLU nie polepszy&#322;o &nbsp;wynik&oacute;w dok&#322;adno&#347;ci.</span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26 c25"><span class="c31 c13"></span></p><p class="c26"><span class="c31 c13">Wykorzystuj&#261;c funkcj&#281; aktywacji PReLU zainspirowano si&#281;:</span></p><p class="c26"><span class="c13 c48 c47">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, Kaiming He et al. (2015)</span></p><p class="c16 c25"><span class="c23 c13"></span></p><p class="c16"><span class="c31 c13">Czy model uproszczony i zoptymalizowany dzia&#322;a istotnie szybciej od modelu odniesienia na CPU/GPU?</span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c16"><span>Modele uproszczone z wykorzystaniem przerzedzania/metody RigL nie dzia&#322;aj&#261; szybciej ani na GPU, ani na CPU. Wynika to z braku wsparcia przyspieszenia inferencji przez bibliotek&#281; PyTorch. Jednak&#380;e zastosowanie przerzedzania/RigL pozwoli&#322;o uzyska&#263; wy&#380;sz&#261; dok&#322;adno&#347;&#263; dzia&#322;ania modelu. Metody upraszczania modelu zadzia&#322;a&#322;y jako </span><span class="c62">regularyzacja</span><span>. Nast&#281;pnie w oparciu o model wytrenowany metod&#261; RigL przeprowadzono </span><span class="c62">destylacj&#281; wiedzy</span><span>&nbsp;do modelu mniejszego. W ten spos&oacute;b uzyskano spadek liczby parametr&oacute;w, czasu inferencji modelu zar&oacute;wno na CPU oraz GPU przy </span><span class="c62">zachowaniu dok&#322;adno&#347;ci</span><span>&nbsp;modelu. </span><span class="c13 c48 c47">Warto zatem &#322;&#261;czy&#263; te techniki. </span></p><p class="c16 c25"><span class="c31 c13"></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230494683&amp;usg=AOvVaw1m_NniU1c2rk4EDl0rCBDP">[1]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;J. Li </a></span><span class="c64 c45"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230495054&amp;usg=AOvVaw0orNKAKTC40d4alIpL7s7X">et al.</a></span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230495364&amp;usg=AOvVaw10WsH4GTIrGG5pXxf9s3b8">, &ldquo;LungAttn: advanced lung sound classification using attention mechanism with dual TQWT and triple STFT spectrogram,&rdquo; </a></span><span class="c64 c45"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230495704&amp;usg=AOvVaw2YeZvCDmmOm0zqaM-i5Npi">Physiol. Meas.</a></span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230495981&amp;usg=AOvVaw3MMFYudvv8xfH-fR5OymxC">, vol. 42, no. 10, p. 105006, Oct. 2021, doi: 10.1088/1361-6579/ac27b9.</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230496618&amp;usg=AOvVaw0_157HF_30gCmvdSQEE2NC">[2]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;SJTU-YONGFU-RESEARCH-GRP/LungAttn.&rdquo; https://github.com/SJTU-YONGFU-RESEARCH-GRP/LungAttn (accessed Aug. 11, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230497186&amp;usg=AOvVaw2p4_ax1d7HT0d3045RNt1F">[3]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;Papers with Code - ICBHI Respiratory Sound Database Benchmark (Audio Classification).&rdquo; https://paperswithcode.com/sota/audio-classification-on-icbhi-respiratory (accessed Aug. 11, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230497670&amp;usg=AOvVaw2wrPLvPF87fZu4saV29Qmo">[4]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;ICBHI 2017 Challenge | ICBHI Challenge.&rdquo; https://bhichallenge.med.auth.gr/ICBHI_2017_Challenge (accessed May 14, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230498152&amp;usg=AOvVaw2lvd58XTYRl3h4U2k7JX6-">[5]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A. Geifman, &ldquo;The Correct Way to Measure Inference Time of Deep Neural Networks,&rdquo; </a></span><span class="c64 c45"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230498457&amp;usg=AOvVaw0hFf_wHQrBF9a2wP21-PnI">Deci</a></span><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230498709&amp;usg=AOvVaw2UNbk1svQJI1BxGQVJWA7w">, May 01, 2023. https://deci.ai/blog/measure-inference-time-deep-neural-networks/ (accessed Aug. 11, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230499163&amp;usg=AOvVaw2kXsvCfjdXEh0GegvNHTmg">[6]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;SGD &mdash; PyTorch 2.0 documentation.&rdquo; https://pytorch.org/docs/stable/generated/torch.optim.SGD.html (accessed Sep. 16, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230499693&amp;usg=AOvVaw13FB8XycLURDqXtTAyo6Uc">[7]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;StepLR &mdash; PyTorch 2.0 documentation.&rdquo; https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html (accessed Sep. 16, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230500100&amp;usg=AOvVaw21ublNa7q-m_MpktP-1R5o">[8]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;BCELoss &mdash; PyTorch 2.0 documentation.&rdquo; https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html (accessed Sep. 16, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230500481&amp;usg=AOvVaw0Ha5CSpZc4BPXw-lQxAs5r">[9]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;Pruning Tutorial &mdash; PyTorch Tutorials 2.0.1+cu117 documentation.&rdquo; https://pytorch.org/tutorials/intermediate/pruning_tutorial.html (accessed Sep. 03, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230500904&amp;usg=AOvVaw017G2mDqqFoGRdSnTeeYXO">[10]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;torch.nn.utils.prune.ln_structured &mdash; PyTorch 2.0 documentation.&rdquo; https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html (accessed Sep. 03, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230501380&amp;usg=AOvVaw3CW4N9cnSZLV4fAGhC8gCo">[11]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;BasePruningMethod &mdash; PyTorch 2.0 documentation.&rdquo; https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod (accessed Sep. 03, 2023).</a></span></p><p class="c14 c20"><span class="c64"><a class="c35" href="https://www.google.com/url?q=https://www.zotero.org/google-docs/?7OffIQ&amp;sa=D&amp;source=editors&amp;ust=1700747230501827&amp;usg=AOvVaw0iyTMlkAETpSe0hqxw68YF">[12]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;U. Evci, T. Gale, J. Menick, P. S. Castro, and E. Elsen, &ldquo;Rigging the Lottery: Making All Tickets Winners.&rdquo; arXiv, Jul. 23, 2021. Accessed: Sep. 11, 2023. [Online]. Available: http://arxiv.org/abs/1911.11134</a></span></p><div><p class="c53 c25 c92"><span class="c31 c13"></span></p></div><div class="c96"><p class="c14"><a href="#cmnt_ref1" id="cmnt1">[a]</a><span class="c31 c13">funkcja straty, optymalizator i hiperparametry modelu</span></p></div></body></html>


# LungAttn
This repository contains the LungAttn for lung sound deep learning classification model, published in [this paper](https://pubmed.ncbi.nlm.nih.gov/34534977/).

<!-- TABLE OF CONTENTS -->
## Table of Contents

* [LungAttn](#LungAttn)
  * [Pre-processing](#Pre-processing)
  * [Augmentation](#Augmentation)
  * [Train](#Train)
  * [Performance](#Performance)
* [Author](#Author)
* [License](#License)

## LungAttn

The architecture of our LungAttn model. The input is a 3-channel spectrogram after tunable-Q wavelet transform (TQWT) and short time Fourier transform (STFT)![image](./picture/architecture.png)

## Pre-processing

In order to train the model, you need to download ICBHI 2017 database [here](https://bhichallenge.med.auth.gr/). Each sample provided by this database contains several breath cycles. So you need to clip them according to the start and end time declared officialy. Then you need to divide them into train set and test set. Here we divide them based on official suggestion.

The class to clip samples and divide database are concluded in
```
LungAttn/pre-processing/tqwt_stft.py
```
named `clip_cycle` and `clip_test` respectively.

After that, we implement tunable-Q wavelet transform (TQWT) to decompose the original lung sound and short time Fourier transform (STFT) to convert the audio into spectrograms. 
![image](./picture/feature.png)
You can run
```
LungAttn/pre-processing/tqwt_stft.py
```
to store the spectrograms as pictures locally. Then
```
LungAttn/pre-processing/pm_pack.py
```
helps you to store spectrograms and corresponding labels into `.p` file.

## Augmentation

To eliminate the imbalanced problem of ICBHI 2017 dataset, we implement mixup data augmentation method. 
![image](./picture/mixup.png)

The implementation of mixup method is included in 
```
LungAttn/model/LungAttn.py
```
named `mixup_data`.

## Train

The model was built using PyTorch, please read detail in 
```
LungAttn/model/LungAttn.py
```
To run the model, you can use the command
```
python3 model/LungAttn.py \
--lr 0.1 \
--gpu 0 \
--nepochs 100 \
--input ../pack/official/tqwt1_4_train.p \
--test ../pack/official/tqwt1_4_test.p \
--batch_size 32 \
--mixup True \
> log/outfile/myout.file 2>&1&
```

## Performance

Comparison with state-of-the art works:

![image](./picture/comparison.png)

Confusion matrix:

![image](./picture/confusion_matrix.png)

## Authors

* **Jizuo Li** 
* **Jiajun Yuan** 
* **Hansong Wang** 
* **Shijian Liu** 
* **Qianyu Guo** 
* **Yi Ma**
* **Yongfu Li***
* **Liebin Zhao***
* **Guoxing Wang**

## License

Please cite these papers if you have used part of this work.
```
Li J, Yuan J, Wang H, et al. LungAttn: advanced lung sound classification using attention mechanism with dual TQWT and triple STFT spectrogram[J]. Physiological Measurement, 2021, 42(10): 105006.
```
